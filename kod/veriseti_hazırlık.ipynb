{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwXjTYLf3XbU","executionInfo":{"status":"ok","timestamp":1723101760040,"user_tz":-180,"elapsed":26857,"user":{"displayName":"ayse erolur","userId":"05738205577310742199"}},"outputId":"018c2a41-e44e-4559-b5b5-7d71147654f4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"GJUaJwsNB9pR","executionInfo":{"status":"ok","timestamp":1723101764331,"user_tz":-180,"elapsed":1756,"user":{"displayName":"ayse erolur","userId":"05738205577310742199"}}},"outputs":[],"source":["import re\n","import csv\n","\n","input_file = '/content/drive/MyDrive/nlp/friends.txt'\n","cleaned_file = '/content/drive/MyDrive/nlp/temizlenmis.txt'\n","output_csv = '/content/drive/MyDrive/nlp/friends.csv'\n","\n","with open(input_file, 'r') as file:\n","    content = file.read()\n","\n","content = re.sub(r'\\[.*?\\]', '', content)\n","content = re.sub(r'\\(.*?\\)', '', content)\n","content = re.sub(r'\\<.*?\\>', '', content)\n","content = re.sub(r'\\{.*?\\}', '', content)\n","\n","with open(cleaned_file, 'w') as file:\n","    file.write(content)\n","\n","with open(cleaned_file, 'r') as file:\n","    lines = file.readlines()\n","\n","with open(output_csv, 'w', newline='') as csvfile:\n","    csv_writer = csv.writer(csvfile)\n","    csv_writer.writerow(['character', 'dialogue'])\n","\n","    for line in lines:\n","        if ':' in line:\n","            parts = line.strip().split(':', 1)\n","            if len(parts) == 2:\n","                character, dialogue = parts\n","                if ',' in character:\n","                    continue\n","                csv_writer.writerow([character, dialogue])\n"]},{"cell_type":"code","source":["import os\n","import glob\n","import pandas as pd\n","\n","merged_file = '/content/drive/MyDrive/nlp/friends.csv'\n","input_directory = '/content/drive/MyDrive/nlp/'\n","all_filenames = glob.glob(os.path.join(input_directory, \"*.csv\"))\n","\n","combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames])\n","combined_csv.to_csv(merged_file, index=False, encoding='utf-8-sig')"],"metadata":{"id":"LMYF1A5gB-tt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_files = [\n","    '/content/drive/MyDrive/nlp/friends_s1.txt',\n","    '/content/drive/MyDrive/nlp/friends_s2.txt',\n","    '/content/drive/MyDrive/nlp/friends_s3.txt',\n","    '/content/drive/MyDrive/nlp/friends_s4.txt',\n","    '/content/drive/MyDrive/nlp/friends_s5.txt',\n","    '/content/drive/MyDrive/nlp/friends_s6.txt',\n","    '/content/drive/MyDrive/nlp/friends_s7.txt',\n","    '/content/drive/MyDrive/nlp/friends_s8.txt',\n","    '/content/drive/MyDrive/nlp/friends_s9.txt',\n","    '/content/drive/MyDrive/nlp/friends_s10.txt'\n","]\n","merged_file = '/content/drive/MyDrive/nlp/merged_friends.txt'\n","\n","merged_content = []\n","\n","for input_file in input_files:\n","    with open(input_file, 'r') as file:\n","        content = file.read()\n","        merged_content.append(content)\n","\n","with open(merged_file, 'w') as file:\n","    for content in merged_content:\n","        file.write(content + '\\n')\n"],"metadata":{"id":"HcwH0ugeCBd3"},"execution_count":null,"outputs":[]}]}
